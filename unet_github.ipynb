{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver tumors segmentation\n",
    "\n",
    "Ahmed El Bajdali - ahmed.el-bajdali@student-cs.fr \\\n",
    "Marouane EL Ouarraq - marouane.el-ouarraq@student-cs.fr \\\n",
    "Cyrielle Théobald - cyrielle.theobald@student-cs.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:02:21.828828Z",
     "iopub.status.busy": "2025-04-16T23:02:21.828359Z",
     "iopub.status.idle": "2025-04-16T23:02:21.837229Z",
     "shell.execute_reply": "2025-04-16T23:02:21.836018Z",
     "shell.execute_reply.started": "2025-04-16T23:02:21.828780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import time \n",
    "\n",
    "from matplotlib.widgets import Slider\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nibabel as nib\n",
    "import logging\n",
    "nib_logger = logging.getLogger(\"nibabel\")\n",
    "nib_logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T21:39:23.476280Z",
     "iopub.status.busy": "2025-04-16T21:39:23.475978Z",
     "iopub.status.idle": "2025-04-16T21:39:23.500399Z",
     "shell.execute_reply": "2025-04-16T21:39:23.499217Z",
     "shell.execute_reply.started": "2025-04-16T21:39:23.476256Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T21:39:23.502207Z",
     "iopub.status.busy": "2025-04-16T21:39:23.501762Z",
     "iopub.status.idle": "2025-04-16T21:39:23.522808Z",
     "shell.execute_reply": "2025-04-16T21:39:23.521476Z",
     "shell.execute_reply.started": "2025-04-16T21:39:23.502177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LiverSegmentationConfig:\n",
    "    \"\"\"Configuration class for liver tumor segmentation\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_dir = '/kaggle/input/liver-tumor-segmentation-part-2/volume_pt6'\n",
    "        self.labels_dir = '/kaggle/input/liver-tumor-segmentation/segmentations'\n",
    "\n",
    "        self.volume_paths = list()\n",
    "        self.seg_paths = list()\n",
    "\n",
    "        # Parameters\n",
    "        self.n_classes = 1\n",
    "        self.window_size = (-20,120)\n",
    "        self.batch_size = 32\n",
    "        self.learning_rate = 1e-3\n",
    "\n",
    "    def _init_paths(self):\n",
    "        \"\"\"Initialize volume and segmentation paths\"\"\"\n",
    "        for file in os.listdir(self.train_dir):\n",
    "            if file.endswith('.nii'):\n",
    "                vol_path = os.path.join(self.train_dir, file)\n",
    "                seg_file = file.replace('volume', 'segmentation')\n",
    "                seg_path = os.path.join(self.labels_dir, seg_file)\n",
    "                \n",
    "                if os.path.exists(seg_path):\n",
    "                    self.volume_paths.append(vol_path)\n",
    "                    self.seg_paths.append(seg_path)\n",
    "        \n",
    "        print(f\"Found {len(self.volume_paths)} volumes and {len(self.seg_paths)} segmentations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T21:39:23.527417Z",
     "iopub.status.busy": "2025-04-16T21:39:23.527082Z",
     "iopub.status.idle": "2025-04-16T21:39:23.578108Z",
     "shell.execute_reply": "2025-04-16T21:39:23.576981Z",
     "shell.execute_reply.started": "2025-04-16T21:39:23.527379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 volumes and 50 segmentations\n",
      "Example of a volume path: /kaggle/input/liver-tumor-segmentation-part-2/volume_pt6/volume-66.nii\n",
      "Example of a segmentation path: /kaggle/input/liver-tumor-segmentation/segmentations/segmentation-66.nii\n"
     ]
    }
   ],
   "source": [
    "config = LiverSegmentationConfig()\n",
    "config._init_paths()\n",
    "\n",
    "print(f\"Example of a volume path: {config.volume_paths[4]}\")\n",
    "print(f\"Example of a segmentation path: {config.seg_paths[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:04:12.006190Z",
     "iopub.status.busy": "2025-04-16T22:04:12.005442Z",
     "iopub.status.idle": "2025-04-16T22:04:12.639922Z",
     "shell.execute_reply": "2025-04-16T22:04:12.638981Z",
     "shell.execute_reply.started": "2025-04-16T22:04:12.006097Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8974ac3f2602472d95ebd8311ed7c1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=43, description='orientation', max=85), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4\n",
    "\n",
    "image_path = config.volume_paths[index]\n",
    "data = nib.load(image_path).get_fdata().transpose(2,1,0)\n",
    "segmentation = nib.load(config.seg_paths[index]).get_fdata().transpose(2,1,0)\n",
    "\n",
    "def update(orientation):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(data[orientation], cmap='gray')\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[1].imshow(segmentation[orientation], cmap='gray')\n",
    "    axes[1].set_title(\"Segmented Image\") \n",
    "    plt.show()\n",
    "\n",
    "interact(update, orientation = widgets.IntSlider(min=0, max=len(data)-1, step=1, value=len(data)//2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:06:40.153162Z",
     "iopub.status.busy": "2025-04-16T23:06:40.152758Z",
     "iopub.status.idle": "2025-04-16T23:06:40.160505Z",
     "shell.execute_reply": "2025-04-16T23:06:40.159162Z",
     "shell.execute_reply.started": "2025-04-16T23:06:40.153131Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(scan: np.ndarray, window: tuple = (-20,120), new_size=256) -> np.ndarray:\n",
    "    \"\"\"Applying windowing for given Data and Normalizing\"\"\"\n",
    "    min_value, max_value = window\n",
    "\n",
    "    scan = cv2.resize(scan, (new_size, new_size), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    windowed_scan = np.clip(scan, min_value, max_value) # Windowing\n",
    "    normalized_scan = ((windowed_scan - min_value) / (max_value - min_value)) # Normalization\n",
    "\n",
    "    return normalized_scan\n",
    "\n",
    "def preprocessing_mask(mask: np.ndarray, new_size=256):\n",
    "    mask = cv2.resize(mask, (new_size, new_size), interpolation = cv2.INTER_AREA)\n",
    "    mask = (mask > 0).astype(np.float32)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T23:06:41.579674Z",
     "iopub.status.busy": "2025-04-16T23:06:41.579172Z",
     "iopub.status.idle": "2025-04-16T23:06:42.251794Z",
     "shell.execute_reply": "2025-04-16T23:06:42.250509Z",
     "shell.execute_reply.started": "2025-04-16T23:06:41.579639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10159fcd11b49c792fb96736f244b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=43, description='slice_id', max=85), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 4\n",
    "\n",
    "image_path = config.volume_paths[index]\n",
    "data = nib.load(image_path).get_fdata().transpose(2,1,0)\n",
    "segmentation = nib.load(config.seg_paths[index]).get_fdata().transpose(2,1,0)\n",
    "\n",
    "def update_with_preprocessing(slice_id):\n",
    "    raw_slice = data[slice_id]\n",
    "    preprocessed = preprocessing(raw_slice)\n",
    "    seg_slice = segmentation[slice_id]\n",
    "    seg_slice = preprocessing_mask(seg_slice)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(raw_slice, cmap='gray')\n",
    "    axes[0].set_title(\"Original Slice\")\n",
    "\n",
    "    axes[1].imshow(preprocessed, cmap='gray')\n",
    "    axes[1].set_title(\"Preprocessed\")\n",
    "\n",
    "    axes[2].imshow(seg_slice, cmap='gray')\n",
    "    axes[2].set_title(\"Segmentation Mask\")\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "interact(update_with_preprocessing, slice_id = widgets.IntSlider(min=0, max=len(data)-1, step=1, value=len(data)//2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:10:28.355766Z",
     "iopub.status.busy": "2025-04-16T22:10:28.355322Z",
     "iopub.status.idle": "2025-04-16T22:10:28.364647Z",
     "shell.execute_reply": "2025-04-16T22:10:28.363062Z",
     "shell.execute_reply.started": "2025-04-16T22:10:28.355736Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SlicesDataset(Dataset):\n",
    "    def __init__(self, volume_paths, seg_paths, transform=preprocessing, transform_mask = preprocessing_mask):\n",
    "        self.volume_paths = volume_paths\n",
    "        self.seg_paths = seg_paths\n",
    "        self.transform = transform\n",
    "        self.slice_info = self._get_slice_info()\n",
    "\n",
    "    def _get_slice_info(self):\n",
    "        slice_info = []\n",
    "        for vol_idx, volume_paths in enumerate(self.volume_paths):\n",
    "            vol = nib.load(volume_paths)\n",
    "            num_slices = vol.shape[2]\n",
    "            for slice_idx in range(num_slices):\n",
    "                slice_info.append((vol_idx, slice_idx))\n",
    "        return slice_info\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slice_info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        vol_idx, slice_idx = self.slice_info[idx]\n",
    "        \n",
    "        vol = nib.load(self.volume_paths[vol_idx]).get_fdata()\n",
    "        seg = nib.load(self.seg_paths[vol_idx]).get_fdata()\n",
    "        \n",
    "        slice_vol = vol[:, :, slice_idx]\n",
    "        slice_seg = seg[:, :, slice_idx]\n",
    "        \n",
    "        X = np.expand_dims(X, axis=0)\n",
    "        Y = np.expand_dims(Y, axis=0)\n",
    "\n",
    "        X = self.transform(X)\n",
    "        Y = self.transform_mask(Y)\n",
    "                    \n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:10:37.619773Z",
     "iopub.status.busy": "2025-04-16T22:10:37.619330Z",
     "iopub.status.idle": "2025-04-16T22:10:37.629172Z",
     "shell.execute_reply": "2025-04-16T22:10:37.627748Z",
     "shell.execute_reply.started": "2025-04-16T22:10:37.619738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(config.volume_paths, config.seg_paths, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:10:40.700512Z",
     "iopub.status.busy": "2025-04-16T22:10:40.700134Z",
     "iopub.status.idle": "2025-04-16T22:10:40.991516Z",
     "shell.execute_reply": "2025-04-16T22:10:40.990617Z",
     "shell.execute_reply.started": "2025-04-16T22:10:40.700483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = SlicesDataset(X_train, Y_train, transform = preprocessing, transform_mask=preprocessing_mask)\n",
    "test_dataset = SlicesDataset(X_test, Y_test, transform = preprocessing, transform_mask=preprocessing_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:10:40.993241Z",
     "iopub.status.busy": "2025-04-16T22:10:40.992828Z",
     "iopub.status.idle": "2025-04-16T22:10:40.999125Z",
     "shell.execute_reply": "2025-04-16T22:10:40.997836Z",
     "shell.execute_reply.started": "2025-04-16T22:10:40.993199Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = config.batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T22:10:42.700158Z",
     "iopub.status.busy": "2025-04-16T22:10:42.699766Z",
     "iopub.status.idle": "2025-04-16T22:10:42.720491Z",
     "shell.execute_reply": "2025-04-16T22:10:42.718962Z",
     "shell.execute_reply.started": "2025-04-16T22:10:42.700129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_channels=1, out_channels=config.n_classes):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        # Encoder path\n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "\n",
    "        # Decoder path\n",
    "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = conv_block(1024, 512)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(512, 256)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, config.n_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool1(x1))\n",
    "        x3 = self.enc3(self.pool2(x2))\n",
    "        x4 = self.enc4(self.pool3(x3))\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(self.pool4(x4))\n",
    "\n",
    "        # Decoder\n",
    "        x = self.upconv4(x)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.dec4(x)\n",
    "\n",
    "        x = self.upconv3(x)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec3(x)\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(outputs, targets, epsilon=1e-8):\n",
    "    \"\"\"\n",
    "    Computes Dice score, Dice loss, IoU, Precision, and Recall.\n",
    "    \n",
    "    Args:\n",
    "        outputs (torch.Tensor): Predicted mask (probabilistic).\n",
    "        target (torch.Tensor): Ground truth mask.\n",
    "        epsilon (float): Small value to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing all computed metrics.\n",
    "    \"\"\"\n",
    "    classification = (outputs > 0.5).float()\n",
    "    targets = targets.float()\n",
    "    \n",
    "    # Dice Score\n",
    "    intersection = torch.sum(classification * targets, dim=(1,2,3))\n",
    "    union = torch.sum(classification, dim=(1,2,3)) + torch.sum(targets, dim=(1,2,3))\n",
    "    dice = ((2. * intersection + epsilon) / (union + epsilon)).mean()\n",
    "\n",
    "    # Dice Loss\n",
    "    bce_loss = nn.functional.binary_cross_entropy_with_logits(outputs, targets)\n",
    "\n",
    "    # IoU\n",
    "    iou_inter = (classification * targets).sum()\n",
    "    iou_union = classification.sum() + targets.sum() - iou_inter\n",
    "    iou = (iou_inter / (iou_union)).item() if iou_union > 0 else 1.0\n",
    "\n",
    "    # Precision\n",
    "    tp = (classification * targets).sum()\n",
    "    fp = (classification * (1 - targets)).sum()\n",
    "    precision = (tp / (tp + fp + epsilon))\n",
    "\n",
    "    # Recall\n",
    "    fn = ((1 - classification) * targets).sum()\n",
    "    recall = (tp / (tp + fn + epsilon))\n",
    "\n",
    "    return {\n",
    "        \"dice_score\": dice.item(),\n",
    "        \"loss\": bce_loss.item(),\n",
    "        \"iou_score\": iou,\n",
    "        \"precision\": precision.item(),\n",
    "        \"recall\": recall.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.functional.binary_cross_entropy_with_logits\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "num_epochs = 100\n",
    "\n",
    "log_file = \"UNet.csv\"  \n",
    "log_fields = [\"epoch\", \"time\", \n",
    "              \"train_loss\", \"val_loss\", \n",
    "              \"dice_train\", \"dice_val\", \n",
    "              \"mIou_train\", \"mIou_val\", \n",
    "              \"precision_train\", \"precision_val\", \n",
    "              \"recall_train\", \"recall_val\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validation_metrics(model, dataloader):\n",
    "    val_loss = 0.0\n",
    "    val_dice = 0.0\n",
    "    val_iou = 0.0\n",
    "    val_recall = 0.0\n",
    "    val_precision = 0.0\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    val_iterator = tqdm(dataloader, desc=f\"Validation...\", leave = False)\n",
    "    with torch.no_grad():\n",
    "        for inputs, segmentation_masks in val_iterator:\n",
    "            inputs = inputs.to(device)\n",
    "            segmentation_masks = segmentation_masks.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            outputs = torch.sigmoid(outputs)\n",
    "\n",
    "            loss = criterion(outputs, segmentation_masks)\n",
    "            \n",
    "            metrics = compute_metrics(outputs, segmentation_masks)\n",
    "            \n",
    "            val_loss += metrics['bce_loss']\n",
    "            val_dice += metrics['score']\n",
    "            val_iou += metrics['iou_score']\n",
    "            val_recall += metrics['recall']\n",
    "            val_precision += metrics['precision']\n",
    "\n",
    "    return (val_loss/ len(dataloader)),(val_dice/ len(dataloader)), (val_iou/ len(dataloader)), (val_recall/ len(dataloader)),(val_precision/ len(dataloader))\n",
    "\n",
    "def log_metrics_to_csv(epoch, epoch_time, train_metrics, val_metrics):\n",
    "    with open(log_file, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=log_fields)\n",
    "        writer.writerow({\n",
    "            \"epoch\": epoch,\n",
    "            \"time\": epoch_time,\n",
    "            \"train_loss\": train_metrics['bce_loss'],\n",
    "            \"val_loss\": val_metrics['bce_loss'],\n",
    "            \"dice_train\": train_metrics['dice'],\n",
    "            \"dice_val\": val_metrics['dice'],\n",
    "            \"mIou_train\": train_metrics['iou'],\n",
    "            \"mIou_val\": val_metrics['iou'],\n",
    "            \"precision_train\": train_metrics['precision'],\n",
    "            \"precision_val\": val_metrics['precision'],\n",
    "            \"recall_train\": train_metrics['recall'],\n",
    "            \"recall_val\": val_metrics['recall']\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_prediction(model, index, orientation=63):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        try:\n",
    "            # Load volume and mask\n",
    "            image_path = config.volume_paths[index]\n",
    "            mask_path = config.seg_paths[index]\n",
    "            data = nib.load(image_path).get_fdata().transpose(2, 1, 0)\n",
    "            mask = nib.load(mask_path).get_fdata().transpose(2, 1, 0)\n",
    "\n",
    "            # Select slice\n",
    "            image_slice = data[orientation]\n",
    "            image_slice = preprocessing(image_slice)\n",
    "            mask_slice = mask[orientation]\n",
    "\n",
    "            # Preprocess (resize, normalize, convert to tensor)\n",
    "            image_tensor = torch.tensor(image_slice, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n",
    "            # image_tensor = F.interpolate(image_tensor, size=(256, 256), mode='bilinear')  # \n",
    "            image_tensor = image_tensor.to(device)\n",
    "\n",
    "            # Prediction\n",
    "            output = torch.sigmoid(model(image_tensor))\n",
    "            pred_mask = (output > 0.5).float().squeeze().cpu().numpy()\n",
    "\n",
    "            # Resize mask_slice to match prediction for fair display\n",
    "            mask_tensor = torch.tensor(mask_slice, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "            mask_tensor = F.interpolate(mask_tensor, size=(256, 256), mode='nearest')\n",
    "            mask_resized = mask_tensor.squeeze().numpy()\n",
    "\n",
    "            # Plot\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(10, 6))\n",
    "            axes[0].imshow(image_tensor.squeeze().cpu(), cmap='gray')\n",
    "            axes[0].set_title(\"Input Image\")\n",
    "            axes[1].imshow(mask_resized, cmap='gray')\n",
    "            axes[1].set_title(\"Ground Truth\")\n",
    "            axes[2].imshow(pred_mask, cmap='gray')\n",
    "            axes[2].set_title(\"Prediction\")\n",
    "            for ax in axes:\n",
    "                ax.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load or process image: {e}\")\n",
    "\n",
    "def run_one_epoch(model, optimizer, criterion, train_dataloader, test_dataloader,\n",
    "                  epoch, best_dice, save_path, checkpoint_path, log_file, log_fields):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    train_iterator = tqdm(enumerate(train_dataloader), total=len(train_dataloader), desc=f\"Epoch {epoch+1}\")\n",
    "    running_metrics = {'loss': 0.0, 'dice': 0.0, 'iou': 0.0, 'precision': 0.0, 'recall': 0.0}\n",
    "\n",
    "    for i, (inputs, masks) in train_iterator:\n",
    "        inputs, masks = inputs.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = torch.sigmoid(model(inputs))\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metrics = compute_metrics(outputs, masks)\n",
    "\n",
    "        running_metrics['loss'] += metrics['dice_loss']\n",
    "        running_metrics['dice'] += metrics['dice_score']\n",
    "        running_metrics['iou'] += metrics['iou_score']\n",
    "        running_metrics['precision'] += metrics['precision']\n",
    "        running_metrics['recall'] += metrics['recall']\n",
    "\n",
    "        avg_metrics = {k: v / (i + 1) for k, v in running_metrics.items()}\n",
    "        train_iterator.set_postfix({\n",
    "            'loss': f\"{avg_metrics['loss']:.4f}\",\n",
    "            'dice': f\"{avg_metrics['dice']:.4f}\",\n",
    "            'miou': f\"{avg_metrics['iou']:.4f}\",\n",
    "            'precision': f\"{avg_metrics['precision']:.4f}\",\n",
    "            'recall': f\"{avg_metrics['recall']:.4f}\"\n",
    "        })\n",
    "\n",
    "    # Validation\n",
    "    val_loss, val_dice, val_iou, val_recall, val_precision = validation_metrics(model, test_dataloader)\n",
    "    val_metrics = {\n",
    "        'loss': val_loss,\n",
    "        'dice': val_dice,\n",
    "        'iou': val_iou,\n",
    "        'precision': val_precision,\n",
    "        'recall': val_recall\n",
    "    }\n",
    "\n",
    "    # Save best model\n",
    "    if val_dice > best_dice:\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        best_dice = val_dice\n",
    "        print(f\"Epoch {epoch+1}: New best model saved with Dice {val_dice:.4f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_dice': best_dice\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    # Log\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    log_metrics_to_csv(epoch, epoch_time, avg_metrics, val_metrics)\n",
    "\n",
    "    return best_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "best_dice = 0\n",
    "\n",
    "with open(log_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=log_fields)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for current_epoch in range(num_epochs):\n",
    "    print(f\"\\n=== Epoch {current_epoch+1} ===\")\n",
    "    best_dice = run_one_epoch(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        epoch=current_epoch,\n",
    "        best_dice=best_dice,\n",
    "        save_path=\"/kaggle/working/trained_unet.pt\",\n",
    "        checkpoint_path=\"/kaggle/working/last_checkpoint.pt\",\n",
    "        log_file=log_file,\n",
    "        log_fields=log_fields\n",
    "    )\n",
    "    if current_epoch%10==0:\n",
    "        visualize_prediction(model, 4, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(log_file)\n",
    "display(df)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Loss \n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(df['epoch'], df['train_loss'], label='Train Loss')\n",
    "plt.plot(df['epoch'], df['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Dice score \n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(df['epoch'], df['dice_train'], label='Train Dice')\n",
    "plt.plot(df['epoch'], df['dice_val'], label='Validation Dice')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('Dice Score Evolution')\n",
    "plt.legend()\n",
    "\n",
    "# IoU \n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(df['epoch'], df['mIou_train'], label='Train IoU')\n",
    "plt.plot(df['epoch'], df['mIou_val'], label='Validation IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('IoU Score')\n",
    "plt.title('IoU Score Evolution')\n",
    "plt.legend()\n",
    "\n",
    "# Precision-Recall \n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df['epoch'], df['precision_train'], label='Train Precision')\n",
    "plt.plot(df['epoch'], df['precision_val'], label='Validation Precision')\n",
    "plt.plot(df['epoch'], df['recall_train'], label='Train Recall')\n",
    "plt.plot(df['epoch'], df['recall_val'], label='Validation Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision and Recall Evolution')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 767686,
     "sourceId": 1327578,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 769463,
     "sourceId": 1327590,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6575546,
     "sourceId": 10620055,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6751135,
     "sourceId": 10867209,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
